# Solving Tridiagonal Systems 

Solving tridiagonal systems efficiently on parallel computers is challenging, because of the inherent dependency between the rows of the system and the low computation-to-communication ratio. A parallel algorithm for the solution of tridiagonal systems is parallel cyclic reduction, initially developed by Hockney, also known as the oddâ€“even reduction method. Parallel cyclic reduction is designed for fine-grained parallelism,
where a thread owns exactly one row of the tridiagonal matrix.

Let us first look at the cyclic reduction algorithm in more detail and consider the tridiagonal system   

$$$
\begin{equation} 
	A x =\begin{pmatrix}
	    b_1 & c_1 &        &        &        &              \\
	    a_2 & b_2 & c_2    &        &        & 0            \\
	        & a_3 & b_3    & c_3    &        &              \\
	        &     & \ddots & \ddots & \ddots &              \\
	        & 0   &        & \ddots & \ddots & c_{n-1} 		\\
	        &     &        &        & a_n    & b_n
	\end{pmatrix}
	\begin{pmatrix}
	    x_1         \\
	    x_2         \\
	    x_3         \\
	    \vdots      \\
	    x_{n-1}     \\
	    x_n
	\end{pmatrix}
	=
	\begin{pmatrix}
	    h_1         \\
	    h_2         \\
	    h_3         \\
	    \vdots      \\
	    h_{n-1}     \\
	    h_n
	\end{pmatrix}
	= h		
\end{equation}

The idea of cyclic reduction is to eliminate variables from adjacent equations and reduce the system recursively until a single equation or a two by two system remains. Consider equation $i$ with its upper and lower equation

$$$
\begin{align} 
	\begin{array}{rcrcrcrcrcl}
	    a_{i-1} x_{i-2} & + & b_{i-1} x_{i-1} & + & c_{i-1} x_{i} &   &                 &   &                 & = & h_{i-1} \\
	                    &   & a_{i} x_{i-1}   & + & b_{i} x_{i}   & + & c_{i} x_{i+1}   &   &                 & = & h_{i}   \\
	                    &   &                 &   & a_{i+1} x_{i} & + & b_{i+1} x_{i+1} & + & c_{i+1} x_{i+2} & = & h_{i+1}
	\end{array}
\end{align}

To eliminate $x_{i-1}$ and $x_{i+1}$ we multiply the first equation with $\alpha_i = -a_i / b_{i-1}$ and the last one with $\gamma_i = -c_i / b_{i+1}$ and sum up the three equations to get

$$$
\begin{equation} 
    a_{i}^{(1)} x_{i-2} + b_{i}^{(1)} x_{i} + c_{i}^{(1)} x_{i+2} = h_{i}^{(1)},
\end{equation}

which refers to every second variable and has the coefficients are given by

$$$
\begin{align} 
    a_{i}^{(1)} & = \alpha_i a_{i-1},                           \\
    b_{i}^{(1)} & = b_i + \alpha_i c_{i-1} + \gamma_i a_{i+1},  \\
    c_{i}^{(1)} & = \gamma_i c_{i+1},                           \\
    h_{i}^{(1)} & = h_{i} + \alpha_i h_{i-1} + \gamma_i h_{i+1}.
\end{align}

Cyclic reduction solves the tridiagonal system in two phases. For explanation purposes we assume that $n = 2^q - 1$ with $q \in \mathbb{N}$. The forward reduction phase starts from the original coefficients and right hand side and recursively calculates new coefficients and right hand sides for reduction levels $l = 1, \ldots, q-1$ by

$$$
\begin{align} 
    a_{i}^{(l)} & = \alpha_i a^{(l-1)}_{i-2^{l-1}},                                                     \\
    b_{i}^{(l)} & = b^{(l-1)}_i + \alpha_i c^{(l-1)}_{i-2^{l-1}} + \gamma_i a^{(l-1)}_{i+2^{l-1}},      \\
    c_{i}^{(l)} & = \gamma_i c^{(l-1)}_{i+2^{l-1}},                                                     \\
    h_{i}^{(l)} & = h^{(l-1)}_{i} + \alpha_i h^{(l-1)}_{i-2^{l-1}} + \gamma_i h^{(l-1)}_{i+2^{l-1}}, \label{equ:tridiag elim 2b}
\end{align}

with

$$$
\begin{equation} 
    \alpha_i = -a_i / b_{i-2^{l-1}}, \quad \gamma_i = -c_i / b_{i+2^{l-1}},
\end{equation}

and index $i$ running through

$$$
\begin{equation} 
    i \in \{k 2^l \mid k = 1, \ldots, 2^{q-2l}\}.
\end{equation}

Each reduction roughly halves the number of equations. At level $q-1$ only one equation remains and we can start the second phase, which performs a backward substitution to find the solution recursively for the levels $l = q, q-1, \ldots, 1$

$$$
\begin{equation} 
    x_i = \frac{1}{b_i^{(l-1)}} \left(h_i^{(l-1)} - a_i^{(l-1)} x_{i - 2^{l-1}} - c_i^{(l-1)} x_{i + 2^{l-1}}\right),
\end{equation}

where $i$ runs through

$$$
\begin{equation}\label{equ:i backward}
    i \in \{2^{l-1} + k 2^l \mid k = 1, \ldots, 2^{q-l} - 1\},
\end{equation}

and $x_0 = 0, x_{2^q} = 0$ whenever used. If we run cyclic reduction on an array of $n$ processors we see from the equations above that $2(q-1)$ nearest-neighbor communications are required. Additional storage requirements can be held to a minimum by overwriting the original tridiagonal system with all reduced systems of equations. Note however, because the equations are solved in parallel, we must use temporary storage to make sure that we always use the right values from the previous reduction level.

Here is the routing diagram of the cyclic reduction algorithm. We denote by $p_i = (a_i, b_i, c_i, h_i)$ the coefficients of a single row $i$ and let $p_0 = (0, 1, 0, 0)$ be the values to handle the boundary condition. Similarly, $p_i^{(l)} = (a_i^{(l)}, b_i^{(l)}, c_i^{(l)}, h_i^{(l)})$ represents the updated coefficients of row $i$ at reduction level $l$. Squares represent the evaluation of the equations in the forward reduction phase, the hexagons correspond to the evaluation of backward substitution. 

<img src="../../content/images/triDiagSolverCyclicReduction.png" width="779" alt="cyclic reduction">

The optimal algorithm on a serial computer must minimize the number of arithmetic operations. On a parallel architecture multiple aspects have to be considered and properly balanced. The optimal parallel algorithm depends on the amount of hardware parallelism of the computer. We can trade computation cost against parallelism to enhance the overall efficiency by better using the hardware infrastructure. If we look at the above cyclic reduction algorithm the amount of parallelism deteriorates in the forward reduction, and vice versa increases in the backward substitution, with every level $l$. The parallel cyclic reduction algorithm is a slight variation, which applies the reduction equations simultaneously to all $n$ equations. The resulting algorithm requires more computations but shows significantly higher parallelism. Another advantage of the parallel cyclic reduction algorithm is a better memory access pattern for GPU devices. The basic cyclic reduction algorithm has a strided access pattern, the stride being doubled in every forward reduction, respectively halved in a backward reduction step. This leads to bank conflicts very soon. 

<img src="../../content/images/triDiagSolverParallelCyclicReduction.png" width="625" alt="cyclic reduction">

# Implementation



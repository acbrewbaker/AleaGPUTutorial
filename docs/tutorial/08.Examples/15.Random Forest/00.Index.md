# Random Forest
This example is an implementation of the machine learning method `Random Forest`. It can be used for categorical or continuous features.
The presented implementation is for the latter case.

Random Forests consist of an ensemble of decision trees combined by [bootstrap-aggregation(bagging)](http://en.wikipedia.org/wiki/Bootstrap_aggregating).
The resulting models might be less transparent than decision trees but have the advantage of being less susceptible to over-fitting.

## Algorithm

As random forests consist of decision trees, we first explain, how to create decision trees. In a second part we look on what we do in addition to tree building in order to get a random forest. Finally we give some overview on how the Parallelization is done on CPU as well as on GPU.

### Building decision trees

Calculate split entropy for all features (e.g. for Iris data set: sepal-length, sepal-width, petal-length, petal-width): so for the sepal-length, take all features and order them by value.
for every split possibility calculate the split entropy:

make histogram based on labels for both branches after split. For both of these branches $b \in \{1,2\}$ calculate the split entropy as:

$\rm{Split}_{b}(T) = \sum_i \frac{T_i}{T} \log_2(\frac{T_i}{T})$,

where $T$, $T_i$ are the number of elements of the histogram, resp bin $i$ of the histogram. And sum up these entropies: $\rm{Split}(T) = \sum_b \rm{Split}_{b}(T)$.

As a simplified example assume we have ten samples for a continuous feature, with labels one, two and three, where 

| feature value (sorted)  | label |
| ------------------------|-------|
|  1                      |  1    |
|  2                      |  2    |
|  3                      |  1    |
|  4                      |  1    |
|  5                      |  1    |
|  6                      |  1    |
|  7                      |  3    |
|  8                      |  3    |
|  9                      |  2    |
| 10                      |  3    |

a split between 6 an 7 would leed to the histograms: lower branch:

| label | counts |
|-------|--------|
| 1     | 5      |
| 2     | 1      |
| 3     | 0      |

and the upper branch:

| label | counts |
|-------|--------|
| 1     | 0      |
| 2     | 1      |
| 3     | 3      |

implying a split-entropy of $0.65 + 0.811 = 1.461$. Calculations for all other splits leads to the following split entropies:

<img src="../../content/images/Entropy.png" width="500" alt="Split entropies.">

where the calculated split after 6 seems has lowest entropy of the non boarder splits and hence is the optimal split position for this feature. The same calculation is done for all the other features and the feature with best split is choosen. After the split, the same algorithm is applied again on both branches, till either all features have the same label, or the maximal three depth has been reached.

### Bagging decision trees to random forests

As decision trees suffer from overfitting (especially very deep ones) the idea is to have many different decision trees and have a majority voting on their results. This decreases the variance of decision trees withouth increasing the bias.

In order to get different trees, randomness is introduced at severel points. 

First every sample gets a weight which is randomly chosen for every tree. The weights are choosen by randomly selecthing n samples from n samples with replacement.
The histograms are then not created by counts, but sums on these weights.

As a second source of randomness, for every split only some (randomly chosen) features are considered.

The result from different trees is selected by majority voting.

### GPU parallelization
Creation of weights is currently not done in parallel, but would work on GPU as well.

The `optimizer` method which returns for every feature the best splitting position and its entropy are parallelized. On CPU the method Array.parrallel.mapi instead of Array.mapi is used.
For the GPU implementation several different kernels were written. The kernel launch time has been reduced by initilaizing them lazily. A second implementation using CUDA-streams has been done (using the same kernels as the normal GPU implementation but different launching functionality) in order to hide the datatransfer behind GPU calculations, see also: [overlapping data transfer and GPU calculations using CUDA streams](http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/).
# Random Forest
This example is an implementation of the machine learning method `Random Forest`. It can be used for categorical or continuous features.
The presented algorithm is for the latter case. 

Random Forests consist of a ensemble of decision trees combined by [bootstrap-aggregation(bagging)](http://en.wikipedia.org/wiki/Bootstrap_aggregating)
resulting models less transparent than decision trees but with the advantage of being less susceptible to over-fitting.

## Algorithm

### Building decision trees

### Bagging decision trees

### GPU parallelization strategy
